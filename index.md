---
layout: default
---

Welcome to my personal site! I am an academic researcher and assistant professor of computer science (CS) working on the **interpretability and transparency of language models (LMs)** and other neural networks, with the goal of increasing their reliability, safety, and performance. I also focus on providing natural language explanations for users of LMs.

Previously, I was a postdoctoral researcher at the Allen Institute for AI (Ai2) and the University of Washington, working with Ashish Sabharwal and Hannaneh Hajishirzi. Before that, I received my M.S. and Ph.D. degrees in CS from Georgia Tech, where I was advised by Mark Riedl.
<!-- I spent time during my PhD at Ai2 working with Ana MarasoviÄ‡, Noah Smith, Swabha Swayamdipta, Jack Hessel, and Yejin Choi; and at Google Brain working with Edward Choi, Gerardo Flores, and Andrew Dai.-->

### [Short Bio for Talks]({{ site.url }}/assets/bio.txt)

### Recent Updates
<div class="updates-box">
  <ul>
    <li><strong>Fall 2025</strong>: Invited talk at the <a href="https://interplay-workshop.github.io/">Interplay workshop</a> at COLM. See you in Montreal!</li>
    <li><strong>Fall 2025</strong>: Starting as an assistant professor in the CS department at the University of Maryland. Go terps!</li>
    <li><strong>Summer 2025</strong>: Congrats to <a href="https://www.linkedin.com/in/alecbunn/">Alec Bunn</a> on having a paper accepted to the ACL 2025 GEM workshop.</li>
    <li><strong>Summer 2025</strong>: Invited talk at University of British Columbia.</li>
    <li><strong>Summer 2025</strong>: Our <a href="https://arxiv.org/abs/2504.13151">Mechanistic Interpretability Benchmark (MIB)</a> was accepted to ICML 2025. Check out the <a href="https://mib-bench.github.io/">website</a> for all the benchmark resources. I am also organizing the <a href="https://actionable-interpretability.github.io/">Actionable Interpretability Workshop</a> at ICML. See you in Vancouver!</li>
    <li><strong>Spring 2025</strong>: <a href="https://openreview.net/forum?id=6NNA0MxhCH">Two</a> <a href="https://openreview.net/forum?id=EDoD3DgivF">papers</a> accepted to ICLR 2025, the former as a spotlight.</li>
    <li><strong>Winter 2024</strong>: Selected as a <a href="https://ml.umd.edu/rising-stars-workshop">Rising Star in Machine Learning</a>.</li>
    <li><strong>Winter 2024</strong>: Recognized as an outstanding area chair at EMNLP 2024.</li>
    <li><strong>Winter 2024</strong>: <a href="https://arxiv.org/abs/2407.12043">Paper</a> proposing a taxonomy for model noncompliance accepted at NeurIPS 2024 Datasets and Benchmarks.</li>
    <li><strong>Winter 2024</strong>: Attending EMNLP in Miami. Checkout our 2 <a href="https://arxiv.org/abs/2311.09605">Findings</a> <a href="https://openreview.net/forum?id=4nFfHw0woo">papers</a> and our <a href="https://openreview.net/forum?id=schAf4BPtD">position paper on mechanistic interpretability</a> at the BlackBoxNLP workshop. Slides from my talk at BlackBoxNLP: <a href="{{ site.url }}/assets/wiegreffe_blackboxnlp_2024.pdf">here</a>.</li>
    <li><strong>Fall 2024</strong>: Attending COLM in Philly.</li>
    <li><strong>Fall 2024</strong>: Selected as a <a href="https://genai-workshop.cs.umass.edu/">Rising Star in Generative AI</a>.</li>
    <li><strong>Summer 2024</strong>: Check out our NAACL 2024 tutorial on <a href="https://explanation-llm.github.io/">Explanation in the Era of Large Language Models</a>. See you in Mexico City!</li>
    <li><strong>Spring 2024</strong>: One paper, <a href="https://arxiv.org/abs/2401.06751">The Unreasonable Effectiveness of Easy Training Data for Hard Tasks</a>, will appear at ACL 2024.</li>
    <li><strong>Spring 2024</strong>: Gave a guest lecture in the graduate-level LLMs course at Washington University in St. Louis.</li>
    <li><strong>Winter 2023</strong>: Recording of Sarthak Jain and I's keynote ("Is Attention = Explanation? Past, Present, and Future") at the Big Picture workshop is available <a href="https://us06web.zoom.us/rec/play/Xp0np80zg8IxSPS_bnXpCBbtM3ffGiP4gT1TMZ3-XGSNhlwIEL8dP0WWLT8YLbjGazumq4vh8q7kL5RZ.Uf8hy5Cejeyk3Jrd?canPlayFromShare=true&from=share_recording_detail&startTime=1701908520000&componentName=rec-play&originRequestUrl=https://us06web.zoom.us/rec/share/RnBM-pPFJKaCxH_4FE0ehJyPw3ZfLxNWe_9SCkylWR40KIDW5y_bey4D_PJ8g2TC.7Dy5zKUm59N50z6y?startTime=1701908520000">here (from 1:57)</a>.</li>
    <li><strong>Winter 2023</strong>: Gave a talk to the Washington State Senate's Environment, Energy, and Technology Committee on "What is AI?".</li>
    <li><strong>Winter 2023</strong>: Recognized as a <a href="https://nips.cc/Conferences/2023/ProgramCommittee#top-reivewers">top reviewer</a> at NeurIPS 2023.</li>
    <li><strong>Winter 2023</strong>: <a href="https://arxiv.org/abs/2305.14596">Two</a> <a href="https://arxiv.org/abs/2305.14956">papers</a> at EMNLP 2023, and giving a keynote at the <a href="https://www.bigpictureworkshop.com/">Big Picture</a> workshop with Sarthak Jain. See you in Singapore!</li>
    <li><strong>Winter 2023</strong>: Selected as a <a href="https://eecsrisingstars2023.cc.gatech.edu/">Rising Star in EECS</a>.</li>
    <li><strong>Winter 2023</strong>: <a href="https://arxiv.org/abs/2303.17651">Self-Refine</a> published at NeurIPS.</li>
    <li><strong>Fall 2023</strong>: Talks at UC Irvine, UCSD, and USC.</li>
    <li><strong>Summer 2023</strong>: <a href="{{ site.url }}/assets/wiegreffe_nlrse_workshop_talk_acl_2023.pdf">Slides</a> and <a href="https://us06web.zoom.us/rec/play/V4A5H-PIcqk41T1aS-ejShSYAo-yQFn0O5dIc8CmMbbA8g4m2CwCI1v9hXtEw0rHS6GvxxMZRHaY1-w-.KErf5RNWLR6deohR?canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fus06web.zoom.us%2Frec%2Fshare%2FRABF5bV1gMx3TD0aH6-9Gn0rcrTwGNzqQQ9Uc8QtzSgxecQvc1qJWv8v-mGBcg.-Hjt45OOFD8UpYWm">recording (from 7:45)</a> of my keynote at the ACL <a href="https://nl-reasoning-workshop.github.io/">Natural Language Reasoning and Structured Explanations</a> workshop are available.</li>
    <li><strong>Summer 2023</strong>: Awarded an <a href="https://2023.aclweb.org/program/best_reviewers/">Outstanding Area Chair</a> award (top 1.5% of reviewers and chairs) at ACL 2023.</li>
    <li><strong>Spring 2023</strong>: Quoted in <a href="https://www.fastcompany.com/90896928/the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work">this article</a> about language model interpretability.</li>
    <li><strong>Fall 2022</strong>: Talks at various NLP groups at the University of Washington (<a href="https://tsvetshop.github.io/">Tsvetshop</a>, <a href="https://h2lab.cs.washington.edu/">H2Lab</a>, and <a href="https://faculty.washington.edu/ebender/">Treehouse</a>).</li>
    <li><strong>Fall 2022</strong>: Two <a href="https://arxiv.org/abs/2204.07693">Findings</a> <a href="https://arxiv.org/abs/2105.01311">papers</a> at EMNLP 2022.</li>
    <li><strong>Fall 2022</strong>: Co-organizing the <a href="https://blackboxnlp.github.io/2022/">BlackBoxNLP</a> workshop at EMNLP 2022. See you in Abu Dhabi!</li>
  </ul>
</div>